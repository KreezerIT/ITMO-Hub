# Лабораторная работа №6. *audio*

**Задача**: классифицировать песни по категориям "rock", "jazz" и "hiphop"  
**Датасет:** [yandex_music_dataset](../Lab_6_audio/yandex_music_dataset)  
Всего песен: 150  
- Использовался [публичный неофициальный API Яндекс Музыки](https://yandex-music.readthedocs.io/en/main/index.html) с токеном из личного кабинета (*по подписке*)

---

## Данные
Соберите датасет аудиозаписей. Можно спарсить данные с сайта или получить через api. Можно устроить краудсорс датасета вместе с однокурсниками

## Идеи задач
Использовать конкретно эти - уже не так интересно. Но для вдохновения подойдет
- классификация вида птицы по ее пению
- классификация жанра песни по ее фрагменту  
  визуализация эмбеддингов может получиться похожей на [everynoise.com](https://everynoise.com/), а лаба похожей на лабу supervised
- поиск похожих исполнителей  
  похоже на пункт выше, должно получиться похоже на лабу unsupervised
- классификация языка/пола/возраста говорящих
- классификация своего голоса на аудиодорожке
- детекция голоса на аудиодорожке  
  по сути, классификация наличия речи в каждой секунде записи
- детекция наличия слова-активации в аудиозаписи. Слушай, Алиса!
- распознавание речи  
  вариант для очень заинтересованных. lstm + cnn, CTC loss

## План действий
1. Соберите датасет аудиозаписей
2. (если нет разметки и она нужна) Разметьте данные  
   Можете использовать [активное обучение](https://neerc.ifmo.ru/wiki/index.php?title=Активное_обучение), чтобы разметить данные полуавтоматически. Не забывайте проверять качество авторазметки
3. Предобработайте аудио  
   Можете использовать мел-кепстральное преобразование из librosa, как разобрано на лекции. Или любое другое. В большинстве задач в результате по каждой аудиозаписи получится последовательность мел-кепстральных коэффициентов. Рекомендуется сохранить их, чтобы не проводить преобразование после каждой перезагрузки jupyter-ноутбука
4. Реализуйте и обучите модель  
   Скорее всего, для решения задачи будет достаточно lstm ячейки. Но можете выбрать CNN или feed-forward нейросеть  
   Следите, чтобы модель не переобучилась. Логируйте метрики обучения и валидации в tensorboard
5. Cоздайте эмбеддинги аудио своего датасета  
   Используйте эмбеддинг из последнего слоя вашей модели. Полученные эмбеддинги отобразите в 2d с помощью tsne/umap. Выделите цветом целевую переменную

## Рекомендации
- не стесняйтесь задавать вопросы в чат курса
- рекомендуемый размер датасета - более 50 записей на класс в случае классификации. Остальные случаи сложно оценить вне контекста задачи
- используйте pytorch.nn.Sequential для слоев модели
- если не получается использовать torch.device(“cuda”) на своей машине, то лучше использовать google colab

Для реализации не обязательно, но рекомендуются эти python библиотеки:
- pytorch
- torchaudio
- librosa
- tensorboard

## Популярные замечания
- используйте конфиг файл для констант
- не коммитить `.idea`
- функции длиннее 20 строк - плохо. Их можно декомпозировать
- не показано, что модель не переобучена. Сравните метрики на train и test

## Теормин
В каждом вопросе про метрики, формулы и тп нужно знать как это рассчитывается и почему формулы именно такие. Зубрить сами формулы не нужно

Преподаватель может задать доп вопрос об использованном вами термине, чтобы понять, что вы понимаете его смысл

1. датасеты LibriSpeech-ASR, LibriVox, CommonVoice: из чего состоят, зачем нужны. Что такое частота дискретизации сигнала? Как влияют на волну изменения ее амплитуды, фазы, частоты?
2. что такое [ряд Фурье](https://ru.wikipedia.org/wiki/Ряд_Фурье)? Как работает дискретное преобразование Фурье?  
   Вот неплохие [иллюстрации](https://proglib.io/p/fourier-transform) по преобразованию
3. как выглядит спектрограмма аудиозаписи? Как ее получить? Что такое мел-шкала? Зачем она нужна?
4. как получить мел-кепстральные коэффициенты (mfcc) для аудиозаписи? Можно ли их использовать в качестве эмбеддингов?
5. как выглядит мел-спектрограмма аудиозаписи? Чем отличается от обычной спектрограммы такой же аудиозаписи?
6. как использовать RNN-ячейки для обработки спектрограмм? Например, как реализовать классификацию аудио?
