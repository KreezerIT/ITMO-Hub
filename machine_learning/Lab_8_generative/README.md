# Лабораторная работа №8. *generative*

**Задача**: Генерация изображений покемонов  
**Размер датасета** - 1024 изображений размером ~100x100 px

- Использовался [PokéApi](https://pokeapi.co/) ([Документация](https://pokeapi.co/docs/v2))

> Запросы +- без ограничений, но бывает выдает ломаные картинки или сырой html. Поэтому в парсере-загрузчике есть fallback на разные error коды и кейсы

---

## Данные
Соберите датасет для обучения генеративной модели. Рекомендуется использовать датасеты из картинок низкого разрешения (до 50x50)

Задача генерации аудио более сложная, но при желании можно разобраться с принципом работы [вокодеров](https://habr.com/ru/articles/465941/) и использовать датасет аудио

Текстовые датасеты в этой лабе использовать нельзя, тк gan и autoencoder сложнее обучать на текстовых данных, а также потому что рекуррентные модели способны генерировать текст без генеративных подходов

Можете спарсить данные, использовать api, взять датасет из своей прошлой лабы (необходимо приложить ссылку на код лабы) или даже взять из открытых источников

## Идеи задач
Использовать конкретно эти - уже нельзя. Но для вдохновения подойдет
- генерация рукописных mnist/fashion mnist/cifar/другие популярные датасеты
- генерация пиксель-артов
- генерация эмоджи

## План действий
1. Соберите датасет  
   Чтобы не упереться в ограничение по вычислительным ресурсам, уменьшите масштаб примеров: для картинок - уменьшите их разрешение
2. Реализуйте и обучите модель  
   Рекомендуется выбирать AutoEncoder (AE) или GAN, поскольку другие типы моделей более сложные  
   Выберите функцию ошибки. Для GAN это adversarial loss. Для AE это может быть L1 loss или более подходящая под задачу
3. Проверьте качество модели  
   Сгенерируйте несколько примеров из случайных латентных векторов. Посмотрите примеры - насколько они похожи на реальные данные?
4. Создайте gif с latent space interpolation  
   Возьмите два примера из датасета: A и Б. Получите их эмбеддинги и постройте 20-50 векторов, интерполирующих перетекание вектора А в вектор Б. На каждый полученный вектор сгенерируйте пример вашей моделью. Полученные изображения соберите в gif, например с помощью imageio.mimsave

## Рекомендации
- не стесняйтесь задавать вопросы в чат курса
- рекомендуемый размер датасета - более 1000 примеров  
  Рекомендации картинок/аудио/etc сложно оценить вне контекста задачи, пишите в чат
- используйте tensorboard. Инициализация занимает пару строк, и это позволит отображать метрики во время обучения модели. Это позволит сразу замечать, когда модель переобучается и останавливать обучение. Это может сэкономить много времени
- используйте pytorch.nn.Sequential для слоев модели
- если не получается использовать torch.device(“cuda”) на своей машине, то лучше использовать google colab

## Теормин
В каждом вопросе про метрики, формулы и тп нужно знать как это рассчитывается и почему формулы именно такие. Зубрить сами формулы не нужно

В вопросах про модели подразумевается: Как устроена, как обучается, какие гиперпараметры, какие требования к данным и к чему уязвима, какие сценарии применения

Преподаватель может задать доп вопрос об использованном вами термине, чтобы понять, что вы понимаете его смысл

1. что такое латентное пространство и latent space interpolation
2. модель GAN. Что такое adversarial loss, discriminator, generator. Как обучить GAN генерации mnist картинок
3. модель AutoEncoder. Что такое bottleneck, encoder, decoder, reconstruction error. Как обучить генерации mnist картинок
4. модель Variational AutoEncoder. Чем отличается от AutoEncoder, как генерирует латентный вектор
5. модель диффузии на [упрощенном примере](https://www.countbayesie.com/blog/2023/4/21/linear-diffusion) линейной диффузии. Из каких моделей состоит, как обучается
6. [transposed convolution](https://programmersought.com/article/1224509238/). Чем отличается от обычной свертки. Как позволяет увеличивать feature map. Гиперпараметры слоя [convTransposed2d](https://docs.pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html)
7. Чем [Deep Convolutional GAN](https://learnopencv.com/deep-convolutional-gan-in-pytorch-and-tensorflow/) отличается от простого GAN
