# Лабораторная №7. *recs*

## Данные
Соберите датасет для обучения персональной рекомендательной модели. Чаще всего, это датасет из как минимум 3 колонок: (user_id, item_id, feedback). Фидбек может быть explicit или implicit

Колонок может быть больше, например:
- timestamp взаимодействия юзера с предметом  
  так интереснее, но будьте аккуратны, чтобы не допустить temporal data leak
- градации фидбека  
  например, юзер лайкает одно видео, а другое может репостнуть. Тогда 2 колонки фидбека. Репост дороже, чем лайк, поэтому фидбек будет иметь больший вес при обучении

Можно спарсить данные с сайта или получить через api. Можно устроить краудсорс датасета вместе с однокурсниками

## Идеи задач
Использовать конкретно эти - уже не так интересно. Но для вдохновения подойдет
- краудсорс мемов  
  можно собрать датасет мемов и попросить каждого однокурсника выбрать те, что ему нравятся. Может набраться сотня респондентов, и 2-7 объектов от каждого. Маленький, но неплохой датасет
- “любимые” у юзера сайта  
  например, у [mangalib](https://mangalib.me) закладки публичные, можно спарсить набор (user_id, item_id, in_favourite, rating)
- контент по лайкам  
  во многих соцсетях можно посмотреть список оценивших пост. Если сообщество небольшое, то можно собрать хороший датасет
- любимые места  
  если город небольшой, то в сервисе Карт этого города будет мало юзеров, оставляющих отзывы. Если каждый юзер оставлял несколько отзывов, то получится обучить рекомендательную модель для них

## План действий
1. Соберите датасет для персональных рекомендаций
2. Проанализируйте данные  
   Посмотрите как минимум:
    1. количества юзеров и предметов
    2. распределение по юзерам: сколько в среднем предметов оценивает юзер
    3. распределение по предметам: сколько в среднем юзеров оценило предмет
    4. распределение оценок: как оценивают товары в сервисе
    5. есть ли выбросы?  
       если предмет оценен только одним юзером или юзер оценил только 1 предмет, то для рекомендаций они бесполезны. Удалите их
3. Реализуйте baseline модель  
   Это может быть top popular. Или матричное разложение, если реализуете нейросетевую модель
4. Разбейте данные  
   Сделайте user-item train-test сплит. Обычный случайный сплит приведет к data leak. Тогда вы не заметите переобучения по метрикам, но модель будет плохой
5. Реализуйте и обучите модель  
   Можете выбрать модель из теормина или более сложную. Следите, чтобы модель не переобучилась. Логируйте метрики на обоих сплитах в ходе обучения. Используйте рекомендательные метрики
6. Cоздайте эмбеддинги юзеров и предметов  
   В случае матричной факторизации, модель целиком состоит из 2 таблиц эмбеддингов. В случае сложностей с нейросетевыми моделями, спросите в чате.  
   Полученные эмбеддинги отобразите в 2d с помощью tsne/umap. Если кластеров не видно, то модель явно обучена недостаточно или есть ошибки
7. Сравните baseline и свою реализацию  
   Приведите метрики, в том числе @k

## Рекомендации
- не стесняйтесь задавать вопросы в чат курса
- рекомендуемый размер датасета - более 3 записей на юзера и более 10 записей на предмет. В датасете не менее 100 юзеров и 100 предметов.  
  Рекомендации картинок/аудио/etc сложно оценить вне контекста задачи, пишите в чат
- используйте pytorch.nn.Sequential для слоев модели
- если не получается использовать torch.device(“cuda”) на своей машине, то лучше использовать google colab

## Теория
В каждом вопросе про метрики, формулы и тп нужно знать как это рассчитывается и почему формулы именно такие. Зубрить сами формулы не нужно

В вопросах про модели подразумевается: Как устроена, как обучается, какие гиперпараметры, какие требования к данным и к чему уязвима, какие сценарии применения

В [yandex ml handbook](https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij) многие вопросы описаны наглядно и подробно

Преподаватель может задать доп вопрос об использованном вами термине, чтобы понять, что вы понимаете его смысл

1. датасеты [movieLens](https://grouplens.org/datasets/movielens/), [netflix prize](https://paperswithcode.com/dataset/netflix-prize#:~:text=Netflix%20Prize%20consists%20of%20about,range%20from%201%20to%205), [pinterest](https://paperswithcode.com/dataset/pinterest): из чего состоят, зачем нужны. Чем отличаются явный и неявный фидбек юзера на предметы
2. user-item-time train-test сплит  
   в других задачах достаточно разбить данные случайным образом. А в рекомендациях разбивают выборку на train и test так, чтобы множество юзеров и предметов в них не пересекалось, и не было temporal data leak. Но зачем?
3. как представить датасет рекомендаций в виде матрицы и как использовать матричную факторизацию для заполнения пустых ячеек
4. модель коллаборативная фильтрация, модель ALS - Alternating Least Squares
5. модель implicit ALS. [Вот](https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe) неплохой материал о ней
6. модель SVD - Singular Value Decomposition
7. тип моделей DSSM - Deep semantic similarity model
8. двухуровневая модель рекомендаций. Какие требования к моделям первого и второго уровня, когда ее выгодно применять и когда нет
9. виды метрик рекомендаций: point-wise, pair-wise, list-wise
10. метрики рекомендаций: precision@k, recall@k, f1@k
11. метрики рекомендаций: map@k - mean average precision, ndcg@k
12. метрики рекомендаций: coverage, personalization(/novelty). Асимптотическая сложность их расчета
13. как реализовать модель рекомендации картинок? А аудиозаписей?
14. проблемы рекомендаций: cold start, popularity bias, negative sampling, exposure bias
